jobs:
  dev:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Code
      uses: actions/checkout@v2
    - env:
        DATABRICKS_HOST: your-databricks-instance-url
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DESTINATION_PATH: /dev/destination/path/
        SOURCE_PATH: /path/to/your/dev_script.py
      name: Copy Dev script to Databricks
      run: databricks workspace import -l PYTHON -f ${{ env.SOURCE_PATH }} -n ${{
        env.DESTINATION_PATH }}
      tags: TEST-ETL, dev
    - env:
        DESTINATION_PATH: /home/ec2-user/destination/path/
        SOURCE_PATH: /path/to/your/dag_file.py
      name: Copy Dag to EC2
      run: scp -i ~/.ssh/ec2_key.pem -r ${{ env.SOURCE_PATH }} ec2-user@${{ secrets.EC2_IP_ADDRESS
        }}:${{ env.DESTINATION_PATH }}
      tags: TEST-ETL, dev
  prod:
    needs: qa
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Code
      uses: actions/checkout@v2
    - env:
        DATABRICKS_HOST: your-databricks-instance-url
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DESTINATION_PATH: /qa/destination/path/
        SOURCE_PATH: /path/to/your/qa_script.py
      name: Copy Prod script to Databricks
      run: databricks workspace import -l PYTHON -f ${{ env.SOURCE_PATH }} -n ${{
        env.DESTINATION_PATH }}
      tags: TEST-ETL, production
    - env:
        DESTINATION_PATH: /home/ec2-user/destination/path/
        SOURCE_PATH: /path/to/your/dag_file.py
      name: Copy Dag to EC2
      run: scp -i ~/.ssh/ec2_key.pem -r ${{ env.SOURCE_PATH }} ec2-user@${{ secrets.EC2_IP_ADDRESS
        }}:${{ env.DESTINATION_PATH }}
      tags: TEST-ETL, production
  qa:
    needs: dev
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Code
      uses: actions/checkout@v2
    - env:
        DATABRICKS_HOST: your-databricks-instance-url
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DESTINATION_PATH: /qa/destination/path/
        SOURCE_PATH: /path/to/your/qa_script.py
      name: Copy QA script to Databricks
      run: databricks workspace import -l PYTHON -f ${{ env.SOURCE_PATH }} -n ${{
        env.DESTINATION_PATH }}
      tags: TEST-ETL, qa
    - env:
        DESTINATION_PATH: /home/ec2-user/destination/path/
        SOURCE_PATH: /path/to/your/dag_file.py
      name: Copy Dag to EC2
      run: scp -i ~/.ssh/ec2_key.pem -r ${{ env.SOURCE_PATH }} ec2-user@${{ secrets.EC2_IP_ADDRESS
        }}:${{ env.DESTINATION_PATH }}
      tags: TEST-ETL, qa
name: My Workflow
'on':
  pull_request:
    branches:
    - main
  push:
    branches:
    - main
